---
name: Make It Real - Mapping AI-Facilitated Gendered Harm
excerpt: Launch announcement for report written with RATI Foundation
author: Tarunima Prabhakar
project: ""
date: 2025-11-03
tags: announcement, synthetic-media, online-harms
cover: ../images/cover-rati-report-make-it-real.png
---
import {Box, Text} from 'grommet'
import {ExternalLink} from "../components/atomic/TattleLinks"

![](../images/hero-rati-report-make-it-real.png)

Today we’re releasing a report, Make it Real, co-authored with the RATI Foundation, which focuses on the rise of AI-generated content, colloquially called ‘deepfakes’, in online harassment.

Drawing from cases reported to Rati's helpline Meri Trustline, the report reveals a concerning trend: while the public conversation often centers on celebrities and politicians targeted through AI, a quieter, more personal crisis is also unfolding. These cases seldom reach the media, family circles, or law enforcement, owing to deep stigma, fear, and trauma.

Unlike celebrities and public figures who face harassment in the open and possess some mediated control over their reputation, many survivors reaching out to Meri Trustline experience harassment in private spaces. Some of the salient findings of the report are:
- The majority of digitally manipulated cases appear to contain some AI based manipulation.
- Unlike the cases of NCII, iIn the majority of the cases involving AIgenerated content the perpetrator and target were not close in the physical world. AI is deployed when the perpetrator doesn’t have access to private information about the individual.
- While digitally manipulated content is also disproportionately targeted towards gender minorities (72% of the cases were targeted towards women), nearly all cases (92%) involving AI were targeted towards women.
- The Trustline team has found that the greatest challenge lies in the overall reporting architecture provided by a platform. On platforms where reporting all content is difficult, such as X, reporting AI-generated content is also difficult. On the other hand, platforms with more expansive definitions of harmful content are more likely to address AI-generated content. Memelike content, which has been a grey zone in platform policies, remains a grey zone even with AI-generated content.
- Reporting the content under the DMCA for copyright infringement has often proven to be more effective in taking down offending content than framing and reporting the abuse under the category of gender-based harm.
- We find the existing legal architecture in India to be sufficient for accounting for the risks of AIGC. The key barriers are in accessing the existing legal provisions. There is a need to build the capacity of personnel across justice and enforcement systems to recognize and respond to manipulated content, in ways that are scientific, sensitive and clear of victimblaming narratives



If you are being harassed online or know someone who is, reach out and seek support
Call or WhatsApp Meri Trustline 6363176363 Monday to Friday 9am to 5pm.


<Box className="w-fit mt-4 px-4 py-2 rounded-lg" background="visuals-1">
    <ExternalLink href="/make-it-real-report.pdf">
        <Text className="text-blue-950 no-underline">
            Read Report
        </Text>
    </ExternalLink>
</Box>